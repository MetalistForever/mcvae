{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.samplers import HMC, MALA, ULA, run_chain\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM():\n",
    "    def __init__(self, locs, covariance_matrices):\n",
    "        self.locs = torch.tensor([], device=locs[0].device)\n",
    "        self.covariance_matrices = torch.tensor([], device=covariance_matrices[0].device)\n",
    "        self.distributions = []\n",
    "        self.device = locs[0].device\n",
    "        for i in range(len(locs)):\n",
    "            self.distributions.append(\n",
    "                torch.distributions.MultivariateNormal(loc=locs[i], covariance_matrix=covariance_matrices[i]))\n",
    "\n",
    "    def log_prob(self, z, x=None):\n",
    "        log_p = torch.tensor([], device=z.device)\n",
    "        for i in range(len(self.distributions)):\n",
    "            log_paux = self.distributions[i].log_prob(z).view(-1, 1)\n",
    "            log_p = torch.cat([log_p, log_paux], dim=-1)\n",
    "        log_density = torch.logsumexp(log_p, dim=1)\n",
    "        return log_density\n",
    "\n",
    "    def sample(self, shape):\n",
    "        p = np.random.choice(a=len(self.distributions), size=shape[0])\n",
    "        samples = torch.tensor([], device=self.device)\n",
    "        for idx in p:\n",
    "            z = self.distributions[idx].sample((1,))\n",
    "            samples = torch.cat([samples, z])\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = [torch.tensor([-1., -1.], device=device, dtype=torch.float32),\n",
    "       torch.tensor([1., 1.], device=device, dtype=torch.float32),]\n",
    "\n",
    "covs = [torch.eye(2, device=device, dtype=torch.float32)*0.1,\n",
    "       torch.eye(2, device=device, dtype=torch.float32)*0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = GMM(locs=locs, covariance_matrices=covs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c1890c792c84582bee177497a30be09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.figure()\n",
    "\n",
    "target_samples = target.sample((5000, )).cpu()\n",
    "plt.scatter(target_samples[:, 0], target_samples[:, 1])\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MALA\n",
    "\n",
    "mala = MALA(step_size=0.3, use_barker=False, learnable=False)\n",
    "z_init = torch.zeros(2, device=device, dtype=torch.float32)[None]\n",
    "\n",
    "mala_samples = run_chain(mala, z_init, target=target.log_prob, n_steps=1000, return_trace=True,).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ULA\n",
    "\n",
    "ula = ULA(step_size=0.05, learnable=False)\n",
    "z_init = torch.zeros(2, device=device, dtype=torch.float32)[None]\n",
    "\n",
    "ula_samples = run_chain(ula, z_init, target=target.log_prob, n_steps=1000, return_trace=True,).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMC\n",
    "\n",
    "hmc = HMC(step_size=0.05, n_leapfrogs=10, learnable=False)\n",
    "z_init = torch.zeros(2, device=device, dtype=torch.float32)[None]\n",
    "\n",
    "hmc_samples = run_chain(hmc, z_init, target=target.log_prob, n_steps=1000, return_trace=True,).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cd4968ad854b93bd546064ea1f3cff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.figure()\n",
    "\n",
    "target_samples = target.sample((5000, )).cpu()\n",
    "plt.scatter(target_samples[:, 0], target_samples[:, 1], color='blue')\n",
    "plt.scatter(mala_samples[:, 0], mala_samples[:, 1], color='red')\n",
    "plt.scatter(ula_samples[:, 0], ula_samples[:, 1], color='green')\n",
    "plt.scatter(hmc_samples[:, 0], hmc_samples[:, 1], color='orange')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
