{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_ula_1 = [88.78, 86.90, 86.41, 86.23, 86.23, 86.13, 86.06, 86.19, 86.07, 85.91]\n",
    "nll_ula_3 = [88.21, 86.57, 86.05, 85.86, 85.94, 85.80, 85.69, 85.79, 85.79, 85.61]\n",
    "nll_ula_5 = [87.67, 85.89, 85.46, 85.30, 85.24, 85.27, 85.29, 85.05, 85.18, 85.02]\n",
    "nll_ula_7 = [88.24, 86.44, 85.70, 85.63, 85.61, 85.50, 85.44, 85.46, 85.38, 85.48]\n",
    "nll_ula_10 = [87.35, 85.76, 85.28, 85.14, 84.83, 85.04, 84.86, 84.86, 84.8, 84.85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_iwae_10 = [88.18, 86.61, 85.94, 85.5, 85.24, 85.11, 85.12, 84.88, 85.23, 84.95] # 84.52\n",
    "nll_vae = [89.01, 87.26, 86.49, 85.85, 85.58, 85.74, 85.33, 85.29, 85.1, 85.14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6041168b5537450fbcc42c7536f51e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(5, 3), dpi=200)\n",
    "plt.plot([1, 3, 5, 10], -1 * np.array([nll_ula_1[-1], nll_ula_3[-1], nll_ula_5[-1], nll_ula_10[-1]]), '-o', label='ULA VAE')\n",
    "# plt.hlines(-nll_vae[-1], -10, 10, linestyle='--', color='red', label='VAE')\n",
    "plt.hlines(-nll_iwae_10[-1], -10, 10, linestyle='--', color='green', label='IWAE')\n",
    "plt.xlabel('Transitions')\n",
    "plt.ylabel('Log likelihood')\n",
    "plt.xlim(1, 10)\n",
    "plt.xticks([1, 3, 5, 7, 10])\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout();\n",
    "plt.savefig('nll.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d5a0f25b6247bdb14f80a161305403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close()\n",
    "plt.figure(figsize=(5, 3), dpi=200)\n",
    "plt.plot(10 * np.arange(10), -np.array(nll_ula_10), '-o', label='ULA VAE (K=10)')\n",
    "plt.plot(10 * np.arange(10), -np.array(nll_vae), '-o', label='VAE', color='red')\n",
    "plt.plot(10 * np.arange(10), -np.array(nll_iwae_10), '-o', label='IWAE (K=10)', color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log likelihood')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout();\n",
    "plt.savefig('nll_training.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on 2d models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import make_dataloaders\n",
    "from models.vaes import Base, VAE, IWAE, AIS_VAE, AIWAE, ULA_VAE, Stacked_VAE, VAE_with_flows\n",
    "from models.samplers import HMC, MALA, ULA, run_chain\n",
    "import yaml\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "colors = {\n",
    "    0: 'blue',\n",
    "    1: 'red',\n",
    "    2: 'green',\n",
    "    3: 'yellow',\n",
    "    4: 'black',\n",
    "    5: 'orange',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = make_dataloaders(dataset='mnist', batch_size=100, val_batch_size=100, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 268 - IWAE\n",
    "# 269 - VAE\n",
    "# 292/293 -- AIS_VAE without/with alpha annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(version):\n",
    "    with open(f'lightning_logs/default/version_{version}/hparams.yaml') as file:\n",
    "        fruits_list = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        print(fruits_list)\n",
    "        hparams = fruits_list\n",
    "        \n",
    "    path = f'lightning_logs/default/version_{version}/checkpoints/'\n",
    "    file_name = os.listdir(path)[0]\n",
    "    checkpoint = torch.load(f'{path}{file_name}')\n",
    "    \n",
    "    for current_model in [VAE, IWAE, ULA_VAE, AIS_VAE]:\n",
    "        try:\n",
    "            model = current_model(**hparams).to(device)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'loaded {model.name}')\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'K': 1, 'acceptance_rate_target': 0.8, 'act_func': <class 'torch.nn.modules.activation.GELU'>, 'beta': None, 'dataset': 'mnist', 'grad_clip_val': 0.0, 'grad_skip_val': 0.0, 'hidden_dim': 2, 'learnable_transitions': False, 'name': 'AIS_VAE', 'net_type': 'conv', 'num_samples': 5, 'shape': 28, 'step_size': 0.01, 'use_alpha_annealing': False, 'use_barker': False, 'use_cloned_decoder': False, 'variance_sensitive_step': True}\n",
      "loaded AIS_VAE\n"
     ]
    }
   ],
   "source": [
    "model = load_model(version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector = torch.randn((10, model.hidden_dim)).to(device)\n",
    "\n",
    "def reconstruct_image(model, pics, num_samples=50):\n",
    "    '''\n",
    "    Function to reconstruct given images\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        z = get_posterior_samples(model, pics.to(device), n_samples=1)\n",
    "        z = torch.tensor(z, device=device, dtype=torch.float32)\n",
    "        pics_rec = torch.sigmoid(model.decode(z)).cpu()\n",
    "    return pics_rec\n",
    "\n",
    "## And let us write a function to generate images:\n",
    "def generate_image(model, random_vector):\n",
    "    with torch.no_grad():\n",
    "        generated = torch.sigmoid(model.decode(random_vector)).cpu()\n",
    "    return generated\n",
    "\n",
    "\n",
    "def plot_digit_samples(original, reconstucted, generated):\n",
    "    \"\"\"\n",
    "    Plot samples from the generative network in a grid\n",
    "    \"\"\"\n",
    "\n",
    "    grid_h = 2\n",
    "    grid_w = 5\n",
    "    data_h = 28\n",
    "    data_w = 28\n",
    "    data_c = 1\n",
    "    plt.close()\n",
    "    fig, ax = plt.subplots(ncols=3, figsize=(5, 3), dpi=200)\n",
    "    images_list = [original, reconstucted, generated]\n",
    "    names = ['original', 'reconstructed', 'generated']\n",
    "    for pos in range(3):\n",
    "        # Turn the samples into one large image\n",
    "        tiled_img = np.zeros((data_h * grid_h, data_w * grid_w))\n",
    "\n",
    "        for idx, image in enumerate(images_list[pos]):\n",
    "            i = idx % grid_w\n",
    "            j = idx // grid_w\n",
    "\n",
    "            top = j * data_h\n",
    "            bottom = (j + 1) * data_h\n",
    "            left = i * data_w\n",
    "            right = (i + 1) * data_w\n",
    "            tiled_img[top:bottom, left:right] = image\n",
    "\n",
    "        # Plot the new image\n",
    "        ax[pos].set_title(names[pos])\n",
    "        ax[pos].axis('off')\n",
    "        ax[pos].imshow(tiled_img, cmap='gray')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_posterior_samples(model, X, n_samples=1000):\n",
    "    '''\n",
    "    The function returns samples from posterior (from encoder for VAE and IWAE, transitions output for ULA/AIS VAEs)\n",
    "    '''\n",
    "    all_samples = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for x in X:\n",
    "            x = x[None].to(device)\n",
    "            model_samples, mu, logvar = model.enc_rep(x=x, n_samples=n_samples)\n",
    "            if model.name in ['ULA_VAE', 'AIS_VAE']:\n",
    "                model_samples_init = model_samples\n",
    "\n",
    "                model_samples = model.run_transitions(z=model_samples, x=x.repeat(n_samples, 1, 1, 1), mu=mu, logvar=logvar)[0]\n",
    "            if all_samples.shape[0] == 0:\n",
    "                all_samples = model_samples.cpu().numpy()[None]\n",
    "            else:\n",
    "                all_samples = np.concatenate([all_samples, model_samples.cpu().numpy()[None]])\n",
    "    return all_samples\n",
    "\n",
    "def plot_image(x):\n",
    "    '''\n",
    "    The function plots given image (tensor) x\n",
    "    '''\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    if x.shape[1] == 1:\n",
    "        plt.imshow(x[0].cpu())\n",
    "    else:\n",
    "        plt.imshow(x.permute((1, 2, 0)).cpu())\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "    \n",
    "def plot_posterior_samples(samples, labels=None):\n",
    "    '''\n",
    "    The function takes given samples of shape [n_objects, n_samples, dims] and plots them, using different colors\n",
    "    '''\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    for i, sampl in enumerate(samples):\n",
    "        plt.scatter(sampl[:, 0], sampl[:, 1], c=colors[i], label=labels[i].item() if labels is not None else None)\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show();\n",
    "    \n",
    "def form_objects(indices):\n",
    "    '''\n",
    "    The function forms pairs (object, labels) from given indices\n",
    "    '''\n",
    "    if not isinstance(indices, list):\n",
    "        indices = [indices]\n",
    "    formed_objects = torch.tensor([])\n",
    "    formed_labels = torch.tensor([])\n",
    "    for i in indices:\n",
    "        formed_objects = torch.cat([formed_objects, batch[i][None]])\n",
    "        formed_labels = torch.cat([formed_labels, labels[i][None]])\n",
    "    return formed_objects, formed_labels\n",
    "\n",
    "def plot_pics_manifold(model, n=15):\n",
    "    '''\n",
    "    The function plots manifold, given model\n",
    "    '''\n",
    "    image_size = 28\n",
    "    figure = np.zeros((image_size * n, image_size * n))\n",
    "    grid_x = norm.ppf(np.linspace(0.05, 0.95, n)).astype(np.float32)\n",
    "    grid_y = norm.ppf(np.linspace(0.05, 0.95, n)).astype(np.float32)\n",
    "\n",
    "    for i, yi in enumerate(grid_x):\n",
    "        for j, xi in enumerate(grid_y):\n",
    "            z_sample = torch.tensor(np.array([[xi, yi]]), dtype=torch.float32, device=model.device)\n",
    "            with torch.no_grad():\n",
    "                x_decoded = torch.sigmoid(model.decode(z_sample)).cpu().numpy()\n",
    "            image = x_decoded[0].reshape(image_size, image_size)\n",
    "            figure[i * image_size: (i + 1) * image_size,\n",
    "                   j * image_size: (j + 1) * image_size] = image\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_cond = \n",
    "for full_batch in val_loader:\n",
    "    batch, labels = full_batch\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025c8d37a41c4eea893f669ef11a8e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(batch[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "formed_objects, formed_labels = form_objects([4, 7, 19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = get_posterior_samples(model, formed_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daea6d4f45e64e288c189f7fa930108d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_posterior_samples(posterior_samples, labels=formed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd294d5820f439593e9599cf1c82a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pics_manifold(model, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddd22a67cc74671b87164f2dc6f912c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reconstructed = reconstruct_image(model, batch[:10], num_samples=1)\n",
    "generated = generate_image(model, random_vector)\n",
    "plot_digit_samples(original=batch[:10], reconstucted=reconstructed, generated=generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
