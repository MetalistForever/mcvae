{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import make_dataloaders\n",
    "from models.vaes import Base, VAE, IWAE, AIS_VAE, ULA_VAE, Stacked_VAE, VAE_with_flows, repeat_data\n",
    "from models.samplers import HMC, MALA, ULA, run_chain\n",
    "import yaml\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "colors = {\n",
    "    0: 'blue',\n",
    "    1: 'red',\n",
    "    2: 'green',\n",
    "    3: 'yellow',\n",
    "    4: 'black',\n",
    "    5: 'orange',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = make_dataloaders(dataset='mnist', batch_size=100, val_batch_size=100, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(version):\n",
    "    with open(f'lightning_logs/default/version_{version}/hparams.yaml') as file:\n",
    "        fruits_list = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        print(fruits_list)\n",
    "        hparams = fruits_list\n",
    "        \n",
    "    path = f'lightning_logs/default/version_{version}/checkpoints/'\n",
    "    file_name = os.listdir(path)[0]\n",
    "    checkpoint = torch.load(f'{path}{file_name}')\n",
    "    \n",
    "    for current_model in [VAE, IWAE, ULA_VAE, AIS_VAE]:\n",
    "        try:\n",
    "            model = current_model(**hparams).to(device)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'loaded {model.name}')\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_func': <class 'torch.nn.modules.activation.GELU'>, 'dataset': 'mnist', 'hidden_dim': 100, 'name': 'IWAE', 'net_type': 'fc', 'num_samples': 50, 'shape': 28, 'sigma': 0.1, 'specific_likelihood': 'gaussian'}\n",
      "loaded IWAE\n"
     ]
    }
   ],
   "source": [
    "version = 794\n",
    "iwae = load_model(version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions_output(model, z, mu, logvar, x):\n",
    "    x = repeat_data(x, model.num_samples)\n",
    "    output = model.run_transitions(z=z,\n",
    "                                    x=x,\n",
    "                                   mu=mu,\n",
    "                                   logvar=logvar)\n",
    "    if len(str(signature(model.loss_function)).split(',')) > 1:\n",
    "        loss = model.loss_function(sum_log_alphas=output[2], sum_log_weights=output[1])\n",
    "    else:\n",
    "        loss = model.loss_function(sum_log_weights=output[1])\n",
    "    import pdb\n",
    "    grad = torch.autograd.grad(loss, model.decoder_net.net[0].bias)[0][:10]\n",
    "    return output, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_W = iwae.decoder_net.net[0].weight.data\n",
    "model_mu = iwae.decoder_net.net[0].bias.data[..., None]\n",
    "\n",
    "C = (model_W @ model_W.T) + (sigma**2) * torch.eye(784, device=device)\n",
    "C_inv = torch.inverse(C)\n",
    "logdetC = torch.logdet(C)\n",
    "\n",
    "first_term = 784 * np.log(2 * np.pi) + logdetC\n",
    "\n",
    "def get_true_loglikelihood(x):\n",
    "    true_loglikelihood = torch.empty(x.shape[0], device=device, dtype=torch.float32)\n",
    "    for i in range(x.shape[0]):\n",
    "        x_cur = x[i].view(784, 1)\n",
    "        S = (x_cur - model_mu) @ (x_cur - model_mu).T\n",
    "        true_loglikelihood[i] = -0.5 * (first_term + torch.trace(C_inv @ S))\n",
    "    return true_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ULA_VAE ----- #\n",
    "ula_vae = ULA_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "            step_size=0.001, K=10, use_transforms=False, learnable_transitions=False, return_pre_alphas=True, use_score_matching=False,\n",
    "                      ula_skip_threshold=0.1, grad_skip_val=0., grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.9, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ula_vae.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ula_vae.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ula_vae.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "\n",
    "# ----- AIS_VAE ----- #\n",
    "ais_vae = AIS_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "                  step_size=0.01, K=10, use_barker=False, learnable_transitions=False, use_alpha_annealing=True, grad_skip_val=0.,\n",
    "                      grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.8, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ais_vae.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ais_vae.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ais_vae.encoder_net = copy.deepcopy(iwae.encoder_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_ula = []\n",
    "Esqr_ula = []\n",
    "E_ula = []\n",
    "grad_elbo_ula = []\n",
    "\n",
    "bias_ais = []\n",
    "Esqr_ais = []\n",
    "E_ais = []\n",
    "grad_elbo_ais = []\n",
    "\n",
    "j = 0\n",
    "for batch in val_loader:\n",
    "    x, _ = batch\n",
    "    x = x.to(device)\n",
    "    z, mu, logvar = iwae.enc_rep(x, 1) # <- latents are fixed\n",
    "    \n",
    "    ula_w = torch.tensor([], device=device, dtype=torch.float32)\n",
    "    ais_w = torch.tensor([], device=device, dtype=torch.float32)\n",
    "    \n",
    "    ula_g = []\n",
    "    ais_g = []\n",
    "    \n",
    "    true_loglikelihood = get_true_loglikelihood(x).cpu().detach().numpy()\n",
    "    \n",
    "    for i in tqdm(range(n)):\n",
    "        ula_log_w, grad_ula = get_transitions_output(ula_vae, z, mu, logvar, x)\n",
    "        ais_log_w, grad_ais = get_transitions_output(ais_vae, z, mu, logvar, x)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ula_log_w = ula_log_w[1]\n",
    "            ais_log_w = ais_log_w[1]\n",
    "\n",
    "            ula_w = torch.cat([ula_w, ula_log_w[..., None]], dim=1)\n",
    "            ais_w = torch.cat([ais_w, ais_log_w[..., None]], dim=1)\n",
    "\n",
    "\n",
    "            ula_g.append(grad_ula.cpu().detach().numpy())\n",
    "            ais_g.append(grad_ais.cpu().detach().numpy())\n",
    "    \n",
    "    log_p_ais = (torch.logsumexp(ais_w, dim=1) - np.log(n)).cpu().detach().numpy()\n",
    "    log_p_ula = (torch.logsumexp(ula_w, dim=1) - np.log(n)).cpu().detach().numpy()\n",
    "    \n",
    "    bias_ula.append(np.mean(log_p_ula - true_loglikelihood))\n",
    "    Esqr_ula.append(np.mean(log_p_ula**2))\n",
    "    E_ula.append(np.mean(log_p_ula))\n",
    "    grad_elbo_ula.append(ula_g)\n",
    "    \n",
    "    bias_ais.append(np.mean(log_p_ais - true_loglikelihood))\n",
    "    Esqr_ais.append(np.mean(log_p_ais**2))\n",
    "    E_ais.append(np.mean(log_p_ais))\n",
    "    grad_elbo_ais.append(ais_g)\n",
    "    \n",
    "    j += 1\n",
    "    if j == 5:\n",
    "        break\n",
    "\n",
    "    \n",
    "l2_ais = np.mean(bias_ais)**2 + np.mean(Esqr_ais) - np.mean(E_ais)**2 + sigma**2\n",
    "l2_ula = np.mean(bias_ula)**2 + np.mean(Esqr_ula) - np.mean(E_ula)**2 + sigma**2\n",
    "\n",
    "\n",
    "grad_elbo_ula = np.std(np.array(grad_elbo_ula))\n",
    "grad_elbo_ais = np.std(np.array(grad_elbo_ais))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_ais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_ula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_elbo_ula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_elbo_ais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
