{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import make_dataloaders\n",
    "from models.vaes import Base, VAE, IWAE, AIS_VAE, ULA_VAE, Stacked_VAE, VAE_with_flows, repeat_data\n",
    "from models.samplers import HMC, MALA, ULA, run_chain\n",
    "import yaml\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "colors = {\n",
    "    0: 'blue',\n",
    "    1: 'red',\n",
    "    2: 'green',\n",
    "    3: 'yellow',\n",
    "    4: 'black',\n",
    "    5: 'orange',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = make_dataloaders(dataset='mnist', batch_size=100, val_batch_size=100, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(version):\n",
    "    with open(f'lightning_logs/default/version_{version}/hparams.yaml') as file:\n",
    "        fruits_list = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        print(fruits_list)\n",
    "        hparams = fruits_list\n",
    "        \n",
    "    path = f'lightning_logs/default/version_{version}/checkpoints/'\n",
    "    file_name = os.listdir(path)[0]\n",
    "    checkpoint = torch.load(f'{path}{file_name}')\n",
    "    \n",
    "    for current_model in [VAE, IWAE, ULA_VAE, AIS_VAE]:\n",
    "        try:\n",
    "            model = current_model(**hparams).to(device)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'loaded {model.name}')\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_func': <class 'torch.nn.modules.activation.GELU'>, 'dataset': 'mnist', 'hidden_dim': 100, 'name': 'IWAE', 'net_type': 'fc', 'num_samples': 50, 'shape': 28, 'sigma': 0.1, 'specific_likelihood': 'gaussian'}\n",
      "loaded IWAE\n"
     ]
    }
   ],
   "source": [
    "version = 794\n",
    "iwae = load_model(version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions_output(model, z, mu, logvar, x):\n",
    "    x = repeat_data(x, model.num_samples)\n",
    "    output = model.run_transitions(z=z,\n",
    "                                    x=x,\n",
    "                                   mu=mu,\n",
    "                                   logvar=logvar)\n",
    "    if len(str(signature(model.loss_function)).split(',')) > 1:\n",
    "        loss = model.loss_function(sum_log_alphas=output[2], sum_log_weights=output[1])\n",
    "    else:\n",
    "        loss = model.loss_function(sum_log_weights=output[1])\n",
    "    import pdb\n",
    "    grad = torch.autograd.grad(loss, model.decoder_net.net[0].bias)[0][:50]\n",
    "    return output, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_W = iwae.decoder_net.net[0].weight.data\n",
    "model_mu = iwae.decoder_net.net[0].bias.data[..., None]\n",
    "\n",
    "C = (model_W @ model_W.T) + (sigma**2) * torch.eye(784, device=device)\n",
    "C_inv = torch.inverse(C)\n",
    "logdetC = torch.logdet(C)\n",
    "\n",
    "first_term = 784 * np.log(2 * np.pi) + logdetC\n",
    "\n",
    "def get_true_loglikelihood(x):\n",
    "    true_loglikelihood = torch.empty(x.shape[0], device=device, dtype=torch.float32)\n",
    "    for i in range(x.shape[0]):\n",
    "        x_cur = x[i].view(784, 1)\n",
    "        S = (x_cur - model_mu) @ (x_cur - model_mu).T\n",
    "        true_loglikelihood[i] = -0.5 * (first_term + torch.trace(C_inv @ S))\n",
    "    return true_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300\n",
    "\n",
    "# ----- ULA_VAE ----- #\n",
    "ula_5 = ULA_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "            step_size=0.001, K=5, use_transforms=False, learnable_transitions=False, return_pre_alphas=True, use_score_matching=False,\n",
    "                      ula_skip_threshold=0.1, grad_skip_val=0., grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.9, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ula_5.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ula_5.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ula_5.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ula_5.use_stepsize_update = False\n",
    "\n",
    "# ----- ULA_VAE ----- #\n",
    "ula_10 = ULA_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "            step_size=0.001, K=10, use_transforms=False, learnable_transitions=False, return_pre_alphas=True, use_score_matching=False,\n",
    "                      ula_skip_threshold=0.1, grad_skip_val=0., grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.9, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ula_10.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ula_10.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ula_10.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ula_10.use_stepsize_update = False\n",
    "\n",
    "\n",
    "\n",
    "# ----- AIS_VAE ----- #\n",
    "ais_5 = AIS_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "                  step_size=0.01, K=5, use_barker=False, learnable_transitions=False, use_alpha_annealing=True, grad_skip_val=0.,\n",
    "                      grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.8, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ais_5.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ais_5.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ais_5.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ais_5.use_stepsize_update = False\n",
    "\n",
    "\n",
    "# ----- AIS_VAE ----- #\n",
    "ais_10 = AIS_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "                  step_size=0.01, K=10, use_barker=False, learnable_transitions=False, use_alpha_annealing=True, grad_skip_val=0.,\n",
    "                      grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.8, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ais_10.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ais_10.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ais_10.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ais_10.use_stepsize_update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(model):\n",
    "    bias_model = []\n",
    "    Esqr_model = []\n",
    "    E_model = []\n",
    "    grad_elbo_model = []\n",
    "\n",
    "    for batch in tqdm(val_loader):\n",
    "        x, _ = batch\n",
    "        x = x.to(device)\n",
    "        z, mu, logvar = iwae.enc_rep(x, 1) # <- latents are fixed\n",
    "\n",
    "        model_w = torch.tensor([], device=device, dtype=torch.float32)\n",
    "\n",
    "        model_g = []\n",
    "\n",
    "        true_loglikelihood = get_true_loglikelihood(x).cpu().detach().numpy()\n",
    "\n",
    "        for i in range(n):\n",
    "            model_log_w, grad_model = get_transitions_output(model, z, mu, logvar, x)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model_log_w = model_log_w[1]\n",
    "\n",
    "                model_w = torch.cat([model_w, model_log_w[..., None]], dim=1)\n",
    "\n",
    "\n",
    "                model_g.append(grad_model.cpu().detach().numpy())\n",
    "\n",
    "        log_p_model = (torch.logsumexp(model_w, dim=1) - np.log(n)).cpu().detach().numpy()\n",
    "\n",
    "        bias_model.append(np.mean(log_p_model - true_loglikelihood))\n",
    "        Esqr_model.append(np.mean(log_p_model**2))\n",
    "        E_model.append(np.mean(log_p_model))\n",
    "        grad_elbo_model.append(model_g)\n",
    "\n",
    "\n",
    "    l2_model = np.mean(bias_model)**2 + np.mean(Esqr_model) - np.mean(E_model)**2 + sigma**2\n",
    "    grad_elbo_model = np.std(np.array(grad_elbo_model))\n",
    "    \n",
    "    \n",
    "    return l2_model, grad_elbo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622ddd52973e465f819d7343b9344bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7692d3b786be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mula_5_l2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mula_5_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_exp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mula_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-8038c4d78c8b>\u001b[0m in \u001b[0;36mrun_exp\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mmodel_log_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_transitions_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-b6b7c869dd45>\u001b[0m in \u001b[0;36mget_transitions_output\u001b[0;34m(model, z, mu, logvar, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_transitions_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepeat_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     output = model.run_transitions(z=z,\n\u001b[0m\u001b[1;32m      4\u001b[0m                                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                    \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/metflow/models/vaes.py\u001b[0m in \u001b[0;36mrun_transitions\u001b[0;34m(self, z, x, mu, logvar)\u001b[0m\n\u001b[1;32m    450\u001b[0m             x=x)\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         output = self.specific_transitions(\n\u001b[0m\u001b[1;32m    453\u001b[0m             \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/metflow/models/vaes.py\u001b[0m in \u001b[0;36mspecific_transitions\u001b[0;34m(self, z, x, init_logdensity, annealing_logdens)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mz_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mK\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             z_transformed, current_log_weights, directions, score_match_cur, forward_grad = self.one_transition(\n\u001b[0m\u001b[1;32m    717\u001b[0m                 \u001b[0mcurrent_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_transformed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/metflow/models/vaes.py\u001b[0m in \u001b[0;36mone_transition\u001b[0;34m(self, current_num, z, x, annealing_logdens, nll)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mz_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             z_new, current_log_weights, directions, score_match_cur, forward_grad = self.transitions[\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mcurrent_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_transition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m                                              \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/metflow/models/samplers.py\u001b[0m in \u001b[0;36mmake_transition\u001b[0;34m(self, z, target, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mtarget_log_density_upd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_upd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mtarget_log_density_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mlog_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_log_density_upd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mproposal_density_numerator\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget_log_density_old\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mproposal_density_denominator\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_jac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             log_1_t = torch.logsumexp(torch.cat([torch.zeros_like(log_t).view(-1, 1),\n",
      "\u001b[0;32m~/github/metflow/models/vaes.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(z, x)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         annealing_logdens = lambda beta: lambda z, x: (1. - beta) * init_logdensity(\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_logdensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             x=x)\n",
      "\u001b[0;32m~/github/metflow/models/vaes.py\u001b[0m in \u001b[0;36mdensity\u001b[0;34m(z, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0mx_reconst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             log_Pr = torch.distributions.Normal(loc=torch.tensor(0., device=x.device, dtype=torch.float32),\n\u001b[0m\u001b[1;32m    155\u001b[0m                                                 \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 z).sum(-1)\n",
      "\u001b[0;32m~/anaconda3/envs/condatorch/lib/python3.8/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlog_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_scale\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ula_5_l2, ula_5_grad = run_exp(ula_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ula_10_l2, ula_10_grad = run_exp(ula_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_5_l2, ais_5_grad = run_exp(ais_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_10_l2, ais_10_grad = run_exp(ais_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
