{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils import make_dataloaders\n",
    "from models.vaes import Base, VAE, IWAE, AIS_VAE, ULA_VAE, Stacked_VAE, VAE_with_flows, repeat_data\n",
    "from models.samplers import HMC, MALA, ULA, run_chain\n",
    "import yaml\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import copy\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "from inspect import signature\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "colors = {\n",
    "    0: 'blue',\n",
    "    1: 'red',\n",
    "    2: 'green',\n",
    "    3: 'yellow',\n",
    "    4: 'black',\n",
    "    5: 'orange',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:58: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:48: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:63: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/nkotelevskii/anaconda3/envs/condatorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:53: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = make_dataloaders(dataset='mnist', batch_size=100, val_batch_size=100, binarize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(version):\n",
    "    with open(f'lightning_logs/default/version_{version}/hparams.yaml') as file:\n",
    "        fruits_list = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        print(fruits_list)\n",
    "        hparams = fruits_list\n",
    "        \n",
    "    path = f'lightning_logs/default/version_{version}/checkpoints/'\n",
    "    file_name = os.listdir(path)[0]\n",
    "    checkpoint = torch.load(f'{path}{file_name}')\n",
    "    \n",
    "    for current_model in [VAE, IWAE, ULA_VAE, AIS_VAE]:\n",
    "        try:\n",
    "            model = current_model(**hparams).to(device)\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "        except:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'loaded {model.name}')\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'act_func': <class 'torch.nn.modules.activation.GELU'>, 'dataset': 'mnist', 'hidden_dim': 100, 'name': 'IWAE', 'net_type': 'fc', 'num_samples': 50, 'shape': 28, 'sigma': 0.1, 'specific_likelihood': 'gaussian'}\n",
      "loaded IWAE\n"
     ]
    }
   ],
   "source": [
    "version = 794\n",
    "iwae = load_model(version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transitions_output(model, z, mu, logvar, x):\n",
    "    x = repeat_data(x, model.num_samples)\n",
    "    output = model.run_transitions(z=z,\n",
    "                                    x=x,\n",
    "                                   mu=mu,\n",
    "                                   logvar=logvar)\n",
    "    if len(str(signature(model.loss_function)).split(',')) > 1:\n",
    "        loss = model.loss_function(sum_log_alphas=output[2], sum_log_weights=output[1])\n",
    "    else:\n",
    "        loss = model.loss_function(sum_log_weights=output[1])\n",
    "    import pdb\n",
    "    grad = torch.autograd.grad(loss, model.decoder_net.net[0].bias)[0][:50]\n",
    "    return output, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_W = iwae.decoder_net.net[0].weight.data\n",
    "model_mu = iwae.decoder_net.net[0].bias.data[..., None]\n",
    "\n",
    "C = (model_W @ model_W.T) + (sigma**2) * torch.eye(784, device=device)\n",
    "C_inv = torch.inverse(C)\n",
    "logdetC = torch.logdet(C)\n",
    "\n",
    "first_term = 784 * np.log(2 * np.pi) + logdetC\n",
    "\n",
    "def get_true_loglikelihood(x):\n",
    "    true_loglikelihood = torch.empty(x.shape[0], device=device, dtype=torch.float32)\n",
    "    for i in range(x.shape[0]):\n",
    "        x_cur = x[i].view(784, 1)\n",
    "        S = (x_cur - model_mu) @ (x_cur - model_mu).T\n",
    "        true_loglikelihood[i] = -0.5 * (first_term + torch.trace(C_inv @ S))\n",
    "    return true_loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ----- ULA_VAE ----- #\n",
    "ula_5 = ULA_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "            step_size=0.001, K=5, use_transforms=False, learnable_transitions=False, return_pre_alphas=True, use_score_matching=False,\n",
    "                      ula_skip_threshold=0.1, grad_skip_val=0., grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.9, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ula_5.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ula_5.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ula_5.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ula_5.use_stepsize_update = False\n",
    "\n",
    "# ----- ULA_VAE ----- #\n",
    "ula_10 = ULA_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "            step_size=0.001, K=10, use_transforms=False, learnable_transitions=False, return_pre_alphas=True, use_score_matching=False,\n",
    "                      ula_skip_threshold=0.1, grad_skip_val=0., grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.9, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ula_10.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ula_10.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ula_10.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ula_10.use_stepsize_update = False\n",
    "\n",
    "\n",
    "\n",
    "# ----- AIS_VAE ----- #\n",
    "ais_5 = AIS_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "                  step_size=0.01, K=5, use_barker=False, learnable_transitions=False, use_alpha_annealing=True, grad_skip_val=0.,\n",
    "                      grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.8, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ais_5.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ais_5.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ais_5.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ais_5.use_stepsize_update = False\n",
    "\n",
    "\n",
    "# ----- AIS_VAE ----- #\n",
    "ais_10 = AIS_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=1, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "                  step_size=0.01, K=10, use_barker=False, learnable_transitions=False, use_alpha_annealing=True, grad_skip_val=0.,\n",
    "                      grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.8, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ais_10.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ais_10.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ais_10.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ais_10.use_stepsize_update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- AIS_VAE ----- #\n",
    "ais_5_3 = AIS_VAE(shape=28, act_func=nn.LeakyReLU, num_samples=3, hidden_dim=iwae.hidden_dim, net_type='fc', dataset='mnist',\n",
    "                  step_size=0.01, K=5, use_barker=False, learnable_transitions=False, use_alpha_annealing=True, grad_skip_val=0.,\n",
    "                      grad_clip_val=0., use_cloned_decoder=False, variance_sensitive_step=False,\n",
    "                     acceptance_rate_target=0.8, annealing_scheme='linear', specific_likelihood='gaussian', sigma=sigma).to(device)\n",
    "ais_5_3.decoder_net = copy.deepcopy(iwae.decoder_net)\n",
    "for p in ais_5_3.decoder_net.parameters():\n",
    "    p.requires_grad_(True)\n",
    "ais_5_3.encoder_net = copy.deepcopy(iwae.encoder_net)\n",
    "ais_5_3.use_stepsize_update = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(model):\n",
    "    bias_model = []\n",
    "    Esqr_model = []\n",
    "    E_model = []\n",
    "    grad_elbo_model = []\n",
    "    \n",
    "    for batch in tqdm(val_loader):\n",
    "        x, _ = batch\n",
    "        x = x.to(device)\n",
    "        z, mu, logvar = iwae.enc_rep(x, model.num_samples) # <- latents are fixed\n",
    "\n",
    "        model_w = torch.tensor([], device=device, dtype=torch.float32)\n",
    "        model_g = []\n",
    "\n",
    "        true_loglikelihood = get_true_loglikelihood(x).repeat(model.num_samples).cpu().detach().numpy()\n",
    "        \n",
    "        for i in range(n):\n",
    "            model_log_w, grad_model = get_transitions_output(model, z, mu, logvar, x)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                model_log_w = model_log_w[1]\n",
    "\n",
    "                model_w = torch.cat([model_w, model_log_w[..., None]], dim=1)\n",
    "\n",
    "\n",
    "                model_g.append(grad_model.cpu().detach().numpy())\n",
    "\n",
    "        log_p_model = (torch.logsumexp(model_w, dim=1) - np.log(n)).cpu().detach().numpy()\n",
    "\n",
    "\n",
    "        bias_model.append(np.mean(log_p_model - true_loglikelihood))\n",
    "        log_p_model = log_p_model.reshape(model.num_samples, -1).mean(0)\n",
    "        Esqr_model.append(np.mean(log_p_model**2))\n",
    "        E_model.append(np.mean(log_p_model))\n",
    "        grad_elbo_model.append(model_g)\n",
    "\n",
    "\n",
    "    l2_model = np.mean(bias_model)**2 + np.mean(Esqr_model) - np.mean(E_model)**2 + sigma**2\n",
    "    grad_elbo_model = np.std(np.array(grad_elbo_model))\n",
    "    \n",
    "    \n",
    "    return l2_model, grad_elbo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec774d4a02ed4410a84cdf9c3514c021",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ula_5_l2, ula_5_grad = run_exp(ula_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ula_10_l2, ula_10_grad = run_exp(ula_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_5_l2, ais_5_grad = run_exp(ais_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_10_l2, ais_10_grad = run_exp(ais_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e62d3dc86cf4229a5147a50aef1a5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ais_5_5_l2, ais_5_5_grad = run_exp(ais_5_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2312143.147093592, 9.114781)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ula_5_l2, ula_5_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2308774.089366896, 9.048041)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ula_10_l2, ula_10_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2324460.4049726967, 9.37676)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais_5_l2, ais_5_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2327962.429088833, 9.374603)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais_10_l2, ais_10_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
